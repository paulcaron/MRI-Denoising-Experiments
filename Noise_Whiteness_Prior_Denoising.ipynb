{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Noise_Whiteness_Prior_Denoising",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN8nZloqU6vH"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSjut2AQU9Yl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.insert(1, '/content/drive/My Drive/personal-deep-decoder')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJaWB13yVFjL"
      },
      "source": [
        "# Decoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1orDYEyDU-3c"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def add_module(self, module):\n",
        "    self.add_module(str(len(self) + 1), module)\n",
        "\n",
        "torch.nn.Module.add = add_module\n",
        "\n",
        "\n",
        "def conv(in_f, out_f, kernel_size, stride=1, pad='zero'):\n",
        "    padder = None\n",
        "    to_pad = int((kernel_size - 1) / 2)\n",
        "    if pad == 'reflection':\n",
        "        padder = nn.ReflectionPad2d(to_pad)\n",
        "        to_pad = 0\n",
        "  \n",
        "    convolver = nn.Conv2d(in_f, out_f, kernel_size, stride, padding=to_pad, bias=False)\n",
        "\n",
        "    layers = filter(lambda x: x is not None, [padder, convolver])\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def decodernw(\n",
        "        num_output_channels=3, \n",
        "        num_channels_up=[128]*5, \n",
        "        filter_size_up=1,\n",
        "        need_sigmoid=True, \n",
        "        pad ='reflection', \n",
        "        upsample_mode='bilinear', \n",
        "        act_fun=nn.ReLU(), # nn.LeakyReLU(0.2, inplace=True) \n",
        "        bn_before_act = False,\n",
        "        bn_affine = True,\n",
        "        upsample_first = True,\n",
        "        ):\n",
        "    \n",
        "    num_channels_up = num_channels_up + [num_channels_up[-1],num_channels_up[-1]]\n",
        "    n_scales = len(num_channels_up) \n",
        "    \n",
        "    if not (isinstance(filter_size_up, list) or isinstance(filter_size_up, tuple)) :\n",
        "        filter_size_up   = [filter_size_up]*n_scales\n",
        "    model = nn.Sequential()\n",
        "\n",
        "    \n",
        "    for i in range(len(num_channels_up)-1):\n",
        "        \n",
        "        if upsample_first:\n",
        "            model.add(conv( num_channels_up[i], num_channels_up[i+1],  filter_size_up[i], 1, pad=pad))\n",
        "            if upsample_mode!='none' and i != len(num_channels_up)-2:\n",
        "                model.add(nn.Upsample(scale_factor=2, mode=upsample_mode))\n",
        "            #model.add(nn.functional.interpolate(size=None,scale_factor=2, mode=upsample_mode))\t\n",
        "        else:\n",
        "            if upsample_mode!='none' and i!=0:\n",
        "                model.add(nn.Upsample(scale_factor=2, mode=upsample_mode))\n",
        "            #model.add(nn.functional.interpolate(size=None,scale_factor=2, mode=upsample_mode))\t\n",
        "            model.add(conv( num_channels_up[i], num_channels_up[i+1],  filter_size_up[i], 1, pad=pad))        \n",
        "        \n",
        "        if i != len(num_channels_up)-1:\t\n",
        "            if(bn_before_act): \n",
        "                model.add(nn.BatchNorm2d( num_channels_up[i+1] ,affine=bn_affine))\n",
        "            model.add(act_fun)\n",
        "            if(not bn_before_act): \n",
        "                model.add(nn.BatchNorm2d( num_channels_up[i+1], affine=bn_affine))\n",
        "      \n",
        "    model.add(conv( num_channels_up[-1], num_output_channels, 1, pad=pad))\n",
        "    if need_sigmoid:\n",
        "        model.add(nn.Sigmoid())\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Residual block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_f, out_f):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_f, out_f, 1, 1, padding=0, bias=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv(x)\n",
        "        out += residual\n",
        "        return out\n",
        "\n",
        "def resdecoder(\n",
        "        num_output_channels=3, \n",
        "        num_channels_up=[128]*5, \n",
        "        filter_size_up=1,\n",
        "        need_sigmoid=True, \n",
        "        pad='reflection', \n",
        "        upsample_mode='bilinear', \n",
        "        act_fun=nn.ReLU(), # nn.LeakyReLU(0.2, inplace=True) \n",
        "        bn_before_act = False,\n",
        "        bn_affine = True,\n",
        "        ):\n",
        "    \n",
        "    num_channels_up = num_channels_up + [num_channels_up[-1],num_channels_up[-1]]\n",
        "    n_scales = len(num_channels_up) \n",
        "    \n",
        "    if not (isinstance(filter_size_up, list) or isinstance(filter_size_up, tuple)) :\n",
        "        filter_size_up   = [filter_size_up]*n_scales\n",
        "\n",
        "    model = nn.Sequential()\n",
        "\n",
        "    for i in range(len(num_channels_up)-2):\n",
        "        \n",
        "        model.add( ResidualBlock( num_channels_up[i], num_channels_up[i+1]) )\n",
        "        \n",
        "        if upsample_mode!='none':\n",
        "            model.add(nn.Upsample(scale_factor=2, mode=upsample_mode))\t\n",
        "            #model.add(nn.functional.interpolate(size=None,scale_factor=2, mode=upsample_mode))\t\n",
        "        \n",
        "        if i != len(num_channels_up)-1:\t\n",
        "            model.add(act_fun)\n",
        "            #model.add(nn.BatchNorm2d( num_channels_up[i+1], affine=bn_affine))\n",
        "                \n",
        "    # new\n",
        "    model.add(ResidualBlock( num_channels_up[-1], num_channels_up[-1]))\n",
        "    #model.add(nn.BatchNorm2d( num_channels_up[-1] ,affine=bn_affine))\n",
        "    model.add(act_fun)\n",
        "    # end new\n",
        "    \n",
        "    model.add(conv( num_channels_up[-1], num_output_channels, 1, pad=pad))\n",
        "    \n",
        "    if need_sigmoid:\n",
        "        model.add(nn.Sigmoid())\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh9kvhlSiI_B"
      },
      "source": [
        "## Study the decoder net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrsK6tBnmDDn"
      },
      "source": [
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP7U8-KPiLtt"
      },
      "source": [
        "k=128\n",
        "num_channels = [k]*6\n",
        "output_depth=1\n",
        "net = decodernw(output_depth ,num_channels_up=num_channels,upsample_first=True).type(torch.cuda.FloatTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkPYvv2siiZl"
      },
      "source": [
        "summary(net, input_size=(k, 16, 16))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSGTVhoc6s5K"
      },
      "source": [
        "##Study the resdecoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg8XPGxq6v6U"
      },
      "source": [
        "net = resdecoder(output_depth, num_channels_up=num_channels).type(torch.cuda.FloatTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW_2_yex6-7A"
      },
      "source": [
        "summary(net, input_size=(64, 16, 16))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0FZmcr2i0rV"
      },
      "source": [
        "# Conv decoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2p_stLKi3M4"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "def add_module(self, module):\n",
        "    self.add_module(str(len(self) + 1), module)\n",
        "\n",
        "torch.nn.Module.add = add_module\n",
        "\n",
        "class conv_model(nn.Module):\n",
        "    def __init__(self, num_layers, strides, num_channels, out_depth, hidden_size, upsample_mode, act_fun, bn_affine=True, bias=False, need_last=False, kernel_size=3):\n",
        "        super(conv_model, self).__init__()\n",
        "        \n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.upsample_mode = upsample_mode\n",
        "        self.act_fun = act_fun\n",
        "        self.layer_inds = [] # record index of the layers that generate output in the sequential mode (after each BatchNorm)\n",
        "        self.combinations = None # this holds input of the last layer which is upsampled versions of previous layers\n",
        "        #self.dtype = dtype\n",
        "\n",
        "        cntr = 1\n",
        "        #torch.set_default_tensor_type(dtype)\n",
        "        net1 = nn.Sequential()\n",
        "        for i in range(num_layers-1):\n",
        "            \n",
        "            net1.add(nn.Upsample(size=hidden_size[i], mode=upsample_mode,align_corners=True))\n",
        "            cntr += 1\n",
        "            \n",
        "            conv = nn.Conv2d(num_channels, num_channels, kernel_size, strides[i], padding=(kernel_size-1)//2, bias=bias)\n",
        "            net1.add(conv)\n",
        "            cntr += 1\n",
        "            \n",
        "            net1.add(act_fun)\n",
        "            cntr += 1\n",
        "            \n",
        "            net1.add(nn.BatchNorm2d( num_channels, affine=bn_affine))\n",
        "            if i != num_layers - 2: # penultimate layer will automatically be concatenated if skip connection option is chosen\n",
        "                self.layer_inds.append(cntr)\n",
        "            cntr += 1\n",
        "\n",
        "        net2 = nn.Sequential()\n",
        "        \n",
        "        nic = num_channels\n",
        "        \n",
        "        if need_last: # orignal code default False, but we call it True\n",
        "            net2.add( nn.Conv2d(nic, num_channels, kernel_size, strides[i], padding=(kernel_size-1)//2, bias=bias) )\n",
        "            net2.add(act_fun)\n",
        "            net2.add(nn.BatchNorm2d( num_channels, affine=bn_affine))\n",
        "            nic = num_channels\n",
        "            \n",
        "        net2.add(nn.Conv2d(nic, out_depth, 1, 1, padding=0, bias=bias))\n",
        "        \n",
        "        self.net1 = net1 # actual convdecoder network\n",
        "        self.net2 = net2 # (default seting) one-layer net converting number of channels\n",
        "        \n",
        "    def forward(self, x, scale_out=1):\n",
        "        ''' run input thru net1 (convdecoder) then net2 (converts number of channels\n",
        "        provide options for skip connections (default False) and scaling factors (default 1) '''\n",
        "        out1 = self.net1(x)\n",
        "        self.combinations = copy.copy(out1)\n",
        "        out2 = self.net2(out1)\n",
        "        return out2*scale_out\n",
        "    def up_sample(self,img):\n",
        "        ''' single upsampling layer '''\n",
        "        samp_block = nn.Upsample(size=self.hidden_size[-1], mode=self.upsample_mode)#,align_corners=True)\n",
        "        img = samp_block(img)\n",
        "        return img\n",
        "\n",
        "def convdecoder(\n",
        "        in_size, #default [16,16]\n",
        "        out_size,#default [256,256]\n",
        "        out_depth, #default 3\n",
        "        num_layers, #default 6\n",
        "        strides, #default [1]*6,\n",
        "        num_channels, #default 64\n",
        "\n",
        "        kernel_size=3,\n",
        "        upsample_mode='nearest', #default 'bilinear', \n",
        "        act_fun=nn.ReLU(), # nn.LeakyReLU(0.2, inplace=True) \n",
        "        bn_affine = True,\n",
        "        nonlin_scales=False,\n",
        "        bias=False,\n",
        "        need_last=True, #False,\n",
        "        ):\n",
        "    \n",
        "    ''' determine how to scale the network based on specified input size and output size\n",
        "        where output hidden_size is size of each hidden layer of network\n",
        "        e.g. input [8,4] and output [640,368] would yield hidden_size of:\n",
        "            [(15, 8), (28, 15), (53, 28), (98, 53), (183, 102), (343, 193), (640, 368)]\n",
        "        provide option for nonlinear scaling (default False) and different activation functions\n",
        "        call conv_model(...), defined above \n",
        "\n",
        "        Note: I removed unnecessary args, e.g. skips, intermeds, pad, etc. \n",
        "              decoder_conv_old.py for original code'''\n",
        "\n",
        "    # scaling factor layer-to-layer in x and y direction\n",
        "    # e.g. (scale_x, scale_y) = (1.87, 1.91)\n",
        "    scale_x,scale_y = (out_size[0]/in_size[0])**(1./(num_layers-1)), (out_size[1]/in_size[1])**(1./(num_layers-1))\n",
        "    \n",
        "    if nonlin_scales: # default false\n",
        "        xscales = np.ceil( np.linspace(scale_x * in_size[0],out_size[0],num_layers-1) )\n",
        "        yscales = np.ceil( np.linspace(scale_y * in_size[1],out_size[1],num_layers-1) )\n",
        "        hidden_size = [(int(x),int(y)) for (x,y) in zip(xscales,yscales)]\n",
        "    else:\n",
        "        hidden_size = [(int(np.ceil(scale_x**n * in_size[0])),\n",
        "                        int(np.ceil(scale_y**n * in_size[1]))) for n in range(1, (num_layers-1))] + [out_size]\n",
        "    #print(hidden_size)\n",
        "    \n",
        "    model = conv_model(num_layers, strides, num_channels, out_depth, hidden_size,\n",
        "                         upsample_mode=upsample_mode, \n",
        "                         act_fun=act_fun,\n",
        "                         bn_affine=bn_affine,\n",
        "                         bias=bias,\n",
        "                         need_last=need_last,\n",
        "                         kernel_size=kernel_size)#,\n",
        "                         #dtype=dtype)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5-wZcEhi8s4"
      },
      "source": [
        "## Visualize convdecoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH4qyts_i_ij"
      },
      "source": [
        "model = convdecoder(\n",
        "        [16,16], #default [16,16]\n",
        "        [512,512],#default [256,256]\n",
        "        1, #default 3\n",
        "        6, #default 6\n",
        "        [1]*6, #default [1]*6,\n",
        "        64, #default 64\n",
        "\n",
        "        kernel_size=3,\n",
        "        upsample_mode='nearest', #default 'bilinear', \n",
        "        act_fun=nn.ReLU(), # nn.LeakyReLU(0.2, inplace=True) \n",
        "        bn_affine = True,\n",
        "        nonlin_scales=False,\n",
        "        bias=False,\n",
        "        need_last=True, #False,\n",
        "        ).type(torch.cuda.FloatTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJJOBkYZPiNT"
      },
      "source": [
        "summary(model, input_size=(64, 16, 16))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvuh_oweVJS_"
      },
      "source": [
        "# Define loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLe0H5A1WEd-"
      },
      "source": [
        "## Reconstruction loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iH_CXE7VHTF"
      },
      "source": [
        "def loss_reconstruction(img, true_img):\n",
        "  mse = torch.nn.MSELoss()\n",
        "  return mse(img, true_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnhLIHwYWGsn"
      },
      "source": [
        "## Autocorrelation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipG8_KT5VueD"
      },
      "source": [
        "def autocorrelation(img):\n",
        "  # shape of img: (B, C, H, W)\n",
        "  B, C, H, W = img.shape\n",
        "  mu = torch.mean(img)\n",
        "  sigma = torch.std(img)\n",
        "  fft = torch.rfft((img-mu)/sigma, signal_ndim=2, onesided=False) # (B, C, H, W, 2)\n",
        "  fft_square = torch.cuda.FloatTensor(B, C, H, W, 2).fill_(0) # (B, C, H, W, 2)\n",
        "  fft_square[:, :, :, :, 0] = fft[:, :, :, :, 0]**2 + fft[:, :, :, :, 1]**2\n",
        "  fast_auto_corr = torch.irfft(fft_square, signal_ndim=2, onesided=False) # (B, C, H, W)\n",
        "  fast_auto_corr = fast_auto_corr/(H*W-1)\n",
        "  return fast_auto_corr\n",
        "\n",
        "def loss_ac(img):\n",
        "  # shape of img: (B, C, H, W)\n",
        "  B, C, H, W = img.shape\n",
        "  autocorr_img = autocorrelation(img)\n",
        "  const_tensor = torch.cuda.FloatTensor(B, C, H, W).fill_(0.)\n",
        "  const_tensor[0, 0, 0, 0] = 1.\n",
        "  auto_corr_loss = (autocorr_img-const_tensor).pow(2).mean()\n",
        "  return auto_corr_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8qytvD50hGJ"
      },
      "source": [
        "## Partial autocorrelation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq_OLTjsr47u"
      },
      "source": [
        "def autocorrelation(img):\n",
        "  # shape of img: (B, C, H, W)\n",
        "  B, C, H, W = img.shape\n",
        "  mu = torch.mean(img)\n",
        "  sigma = torch.std(img)\n",
        "  fft = torch.rfft((img-mu)/sigma, signal_ndim=2, onesided=False) # (B, C, H, W, 2)\n",
        "  fft_square = torch.cuda.FloatTensor(B, C, H, W, 2).fill_(0) # (B, C, H, W, 2)\n",
        "  fft_square[:, :, :, :, 0] = fft[:, :, :, :, 0]**2 + fft[:, :, :, :, 1]**2\n",
        "  fast_auto_corr = torch.irfft(fft_square, signal_ndim=2, onesided=False) # (B, C, H, W)\n",
        "  fast_auto_corr = fast_auto_corr/(H*W-1)\n",
        "  return fast_auto_corr\n",
        "\n",
        "def loss_partial_ac(img):\n",
        "  # shape of img: (B, C, H, W)\n",
        "  B, C, H, W = img.shape\n",
        "  autocorr_img = autocorrelation(img)\n",
        "  const_tensor = torch.cuda.FloatTensor(B, C, H, W).fill_(0.)\n",
        "  const_tensor[0, 0, 0, 0] = 1.\n",
        "  auto_corr_loss = (autocorr_img-const_tensor)[:, :, :10, :10].pow(2).mean()\n",
        "  return auto_corr_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_TAwanXW7WL"
      },
      "source": [
        "## Total variation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPEHC0PpWVRn"
      },
      "source": [
        "def loss_tv(img):\n",
        "  # shape of img: (B, C, H, W)\n",
        "  B, C, H, W = img.shape\n",
        "  tv_h = torch.abs(img[:,:,1:,:]-img[:,:,:-1,:]).sum()\n",
        "  tv_w = torch.abs(img[:,:,:,1:]-img[:,:,:,:-1]).sum()\n",
        "  return (tv_h+tv_w)/((H-1)*(W-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiRXiQD1YN5C"
      },
      "source": [
        "# Define fit function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXMIDsBpYPR6"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import torch.optim\n",
        "import copy\n",
        "import numpy as np\n",
        "from scipy.linalg import hadamard\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from helpers import *\n",
        "\n",
        "dtype = torch.cuda.FloatTensor\n",
        "#dtype = torch.FloatTensor\n",
        "           \n",
        "\n",
        "def exp_lr_scheduler(optimizer, epoch, init_lr=0.001, lr_decay_epoch=500):\n",
        "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
        "    lr = init_lr * (0.65**(epoch // lr_decay_epoch))\n",
        "\n",
        "    if epoch % lr_decay_epoch == 0:\n",
        "        print('LR is set to {}'.format(lr))\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def fit(net,\n",
        "        img_noisy_var,\n",
        "        num_channels,\n",
        "        img_clean_var,\n",
        "        loss_type='l2',\n",
        "        num_iter = 5000,\n",
        "        LR = 0.01,\n",
        "        OPTIMIZER='adam',\n",
        "        opt_input = False,\n",
        "        reg_noise_std = 0,\n",
        "        reg_noise_decayevery = 100000,\n",
        "        mask_var = None,\n",
        "        apply_f = None,\n",
        "        lr_decay_epoch = 0,\n",
        "        net_input = None,\n",
        "        net_input_gen = \"random\",\n",
        "        find_best=False,\n",
        "        weight_decay=0,\n",
        "        lambda_ac=0,\n",
        "        lambda_tv=0,\n",
        "        debug=False\n",
        "       ):\n",
        "  \n",
        "    if not loss_type in ['l1', 'l2']:\n",
        "      print(\"Error: loss_type is {} but should be either l1 or l2\".format(loss_type))\n",
        "\n",
        "    if net_input is not None:\n",
        "        print(\"input provided\")\n",
        "    else:\n",
        "        # feed uniform noise into the network \n",
        "        totalupsample = 2**len(num_channels)\n",
        "        width = int(img_clean_var.data.shape[2]/totalupsample)\n",
        "        height = int(img_clean_var.data.shape[3]/totalupsample)\n",
        "        shape = [1,num_channels[0], width, height]\n",
        "        print(\"shape: \", shape)\n",
        "        net_input = Variable(torch.zeros(shape))\n",
        "        net_input.data.uniform_()\n",
        "        net_input.data *= 1./10\n",
        "    \n",
        "    print(net_input.shape)\n",
        "\n",
        "    net_input_saved = net_input.data.clone()\n",
        "    noise = net_input.data.clone()\n",
        "    p = [x for x in net.parameters() ]\n",
        "\n",
        "    if(opt_input == True): # optimizer over the input as well\n",
        "        net_input.requires_grad = True\n",
        "        p += [net_input]\n",
        "\n",
        "    mse_wrt_noisy = np.zeros(num_iter)\n",
        "    mse_wrt_truth = np.zeros(num_iter)\n",
        "\n",
        "    if OPTIMIZER == 'SGD':\n",
        "        print(\"optimize with SGD\", LR)\n",
        "        optimizer = torch.optim.SGD(p, lr=LR,momentum=0.9,weight_decay=weight_decay)\n",
        "    elif OPTIMIZER == 'adam':\n",
        "        print(\"optimize with adam\", LR)\n",
        "        optimizer = torch.optim.Adam(p, lr=LR,weight_decay=weight_decay)\n",
        "    elif OPTIMIZER == 'LBFGS':\n",
        "        print(\"optimize with LBFGS\", LR)\n",
        "        optimizer = torch.optim.LBFGS(p, lr=LR)\n",
        "\n",
        "    mse = torch.nn.MSELoss() #.type(dtype) \n",
        "    noise_energy = mse(img_noisy_var, img_clean_var)\n",
        "\n",
        "    if find_best:\n",
        "        best_net = copy.deepcopy(net)\n",
        "        best_loss = 1000000.\n",
        "        best_iter = 0\n",
        "\n",
        "    for i in range(num_iter):\n",
        "        \n",
        "        if lr_decay_epoch is not 0:\n",
        "            optimizer = exp_lr_scheduler(optimizer, i, init_lr=LR, lr_decay_epoch=lr_decay_epoch)\n",
        "        if reg_noise_std > 0:\n",
        "            if i % reg_noise_decayevery == 0:\n",
        "                reg_noise_std *= 0.7\n",
        "            net_input = Variable(net_input_saved + (noise.normal_() * reg_noise_std))\n",
        "        \n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            out = net(net_input.type(dtype))\n",
        "\n",
        "            # training loss \n",
        "            \"\"\"\n",
        "            if mask_var is not None:\n",
        "                loss = mse( out * mask_var , img_noisy_var * mask_var )\n",
        "            elif apply_f:\n",
        "                loss = mse( apply_f(out) , img_noisy_var )\n",
        "            else:\n",
        "                loss = mse(out, img_noisy_var)\n",
        "            \"\"\"\n",
        "\n",
        "            if loss_type == 'l2':\n",
        "              l_loss = loss_reconstruction(out, img_noisy_var)\n",
        "            else:\n",
        "              l_loss = torch.abs(out-img_noisy_var).sum()\n",
        "            #ac_loss = loss_ac(img_noisy_unclipped_var-out)\n",
        "            ac_loss = loss_partial_ac(img_noisy_var-out)\n",
        "            tv_loss = loss_tv(out)\n",
        "            loss = l_loss + lambda_ac*ac_loss + lambda_tv*tv_loss\n",
        "            # Adding\n",
        "            \n",
        "            if i%100==0:\n",
        "                print(\"{} iterations: loss={}\".format(i, loss))\n",
        "                if debug:\n",
        "                  print(\"    l_loss: {}\".format(l_loss))\n",
        "                  print(\"    AC loss: {}\".format(ac_loss))\n",
        "                  print(\"    TV loss: {}\".format(tv_loss))\n",
        "                if out.shape[1] != 1:\n",
        "                  plt.imshow(np.clip(out.data.cpu().numpy()[0].transpose(1, 2, 0), 0, 1))\n",
        "                else:\n",
        "                  plt.imshow(np.clip(out.data.cpu().numpy()[0][0, :, :], 0, 1), cmap='gray')\n",
        "                plt.show()\n",
        "                #save_np_img(out.data.cpu().numpy()[0], '/content/drive/My Drive/personal-deep-decoder/saved_images/iter_{}'.format(i))\n",
        "                \n",
        "            \n",
        "            loss.backward()\n",
        "            mse_wrt_noisy[i] = loss.data.cpu().numpy()\n",
        "            \n",
        "            \n",
        "            # the actual loss \n",
        "            true_loss = mse(Variable(out.data, requires_grad=False), img_clean_var)\n",
        "            mse_wrt_truth[i] = true_loss.data.cpu().numpy()\n",
        "            if i % 10 == 0:\n",
        "                out2 = net(Variable(net_input_saved).type(dtype))\n",
        "                loss2 = mse(out2, img_clean_var)\n",
        "                print ('Iteration %05d    Train loss %f  Actual loss %f Actual loss orig %f  Noise Energy %f' % (i, loss.data,true_loss.data,loss2.data,noise_energy.data), '\\r', end='')\n",
        "            return loss\n",
        "\n",
        "        \n",
        "        #if OPTIMIZER == 'LBFGS':\n",
        "        #    if i < 100:\n",
        "        #        optimizer = torch.optim.Adam(p, lr=LR)\n",
        "        #    else:\n",
        "        #        optimizer = torch.optim.LBFGS(p, lr=LR)\n",
        "        \n",
        "        \n",
        "        loss = optimizer.step(closure)\n",
        "            \n",
        "        if find_best:\n",
        "            # if training loss improves by at least one percent, we found a new best net\n",
        "            if best_loss > 1.005*loss.data:\n",
        "                best_loss = loss.data\n",
        "                best_net = copy.deepcopy(net)\n",
        "                best_iter = i\n",
        "                 \n",
        "        \n",
        "    if find_best:\n",
        "        net = best_net\n",
        "        print(\"Best loss at iteration {}\".format(best_iter))\n",
        "    return mse_wrt_noisy, mse_wrt_truth,net_input_saved, net\n",
        "\n",
        "        ### weight regularization\n",
        "        #if orth_reg > 0:\n",
        "        #    for name, param in net.named_parameters():\n",
        "                # consider all the conv weights, but the last one which only combines colors\n",
        "        #        if '.1.weight' in name and str( len(net)-1 ) not in name:\n",
        "        #            param_flat = param.view(param.shape[0], -1)\n",
        "        #            sym = torch.mm(param_flat, torch.t(param_flat))\n",
        "        #            sym -= Variable(torch.eye(param_flat.shape[0])).type(dtype)\n",
        "        #            loss = loss + (orth_reg * sym.sum().type(dtype) )\n",
        "        ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKl8roD8Z9qB"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJpHSuhSZ5s2"
      },
      "source": [
        "path = '/content/drive/My Drive/Full_Images/'\n",
        "img_name = \"img_54\"\n",
        "\n",
        "img_path = path + img_name + \".png\"\n",
        "img_pil = Image.open(img_path)\n",
        "#img_np = pil_to_np(img_pil)\n",
        "#Start\n",
        "img_np = pil_to_np(img_pil)\n",
        "img_np = img_np[0].reshape((1, img_np.shape[1], img_np.shape[2]))\n",
        "img_np = img_np[:, 2:-2, :]\n",
        "#Start\n",
        "img_clean_var = np_to_var(img_np).type(dtype)\n",
        "\n",
        "def get_noisy_img(sig=15, noise_same = False):\n",
        "    sigma = sig/255.\n",
        "    if noise_same: # add the same noise in each channel\n",
        "        noise = np.random.normal(scale=sigma, size=img_np.shape[1:])\n",
        "        noise = np.array( [noise]*img_np.shape[0] )\n",
        "    else: # add independent noise in each channel\n",
        "        noise = np.random.normal(scale=sigma, size=img_np.shape)\n",
        "\n",
        "    img_noisy_np = np.clip(img_np+noise, 0, 1).astype(np.float32)\n",
        "    img_noisy_var = np_to_var(img_noisy_np).type(dtype)\n",
        "    return img_noisy_np, img_noisy_var\n",
        "\n",
        "\n",
        "img_noisy_np, img_noisy_var = get_noisy_img()  \n",
        "output_depth = img_np.shape[0] \n",
        "print(\"Image size: \", img_np.shape)\n",
        "\n",
        "def denoise(img_noisy_var, k=128, numit = 1900, rn = 0.0, find_best=True, upsample_first = True, loss_type='l2', lambda_ac=0, lambda_tv=0, debug=False):\n",
        "    output_depth = img_noisy_var.shape[3]\n",
        "    num_channels = [k]*5\n",
        "    net = decodernw(output_depth, num_channels_up=num_channels,upsample_first=upsample_first).type(dtype)\n",
        "    #net = resdecoder(output_depth, num_channels_up=num_channels).type(dtype)\n",
        "    #net = convdecoder([16,16], list(img_np.shape), 1, 6, [1]*6, k, kernel_size=3, upsample_mode='bilinear', act_fun=nn.ReLU()).type(dtype)\n",
        "\n",
        "\n",
        "    mse_n, mse_t, ni, net = fit(\n",
        "                        net=net,\n",
        "                        num_channels=num_channels,\n",
        "                        reg_noise_std=rn,\n",
        "                        num_iter=numit,\n",
        "                        img_noisy_var=img_noisy_var,\n",
        "                        img_clean_var=img_clean_var,\n",
        "                        find_best=find_best,\n",
        "                        loss_type=loss_type,\n",
        "                        lambda_ac=lambda_ac,\n",
        "                        lambda_tv=lambda_tv,\n",
        "                        debug=debug\n",
        "                        )\n",
        "    out_img_np = net( ni.type(dtype) ).data.cpu().numpy()[0]\n",
        "    return out_img_np, mse_t\n",
        "\n",
        "def myimgshow(plt,img):\n",
        "  if img.shape[0]!=1:\n",
        "    plt.imshow(np.clip(img.transpose(1, 2, 0), 0, 1))\n",
        "  else:\n",
        "    plt.imshow(np.clip(img[0, :, :], 0, 1), cmap='gray')\n",
        "\n",
        "\n",
        "def plot_results(out_img_np, img_np, img_noisy_np):\n",
        "    fig = plt.figure(figsize = (15,15)) # create a 5 x 5 figure \n",
        "    \n",
        "    ax1 = fig.add_subplot(131)\n",
        "    myimgshow(ax1, img_np) \n",
        "    ax1.set_title('Original image')\n",
        "    ax1.axis('off')\n",
        "    \n",
        "    ax2 = fig.add_subplot(132)\n",
        "    myimgshow(ax2, img_noisy_np)\n",
        "    ax2.set_title( \"Noisy observation, PSNR: %.2f\" % psnr(img_np, img_noisy_np) )\n",
        "    ax2.axis('off')\n",
        "\n",
        "    ax3 = fig.add_subplot(133)\n",
        "    myimgshow(ax3, out_img_np)\n",
        "    ax3.set_title( \"Denoised image, SNR: %.2f\" % psnr(img_np, out_img_np) ) \n",
        "    ax3.axis('off')    \n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gZOW5CGqdVC"
      },
      "source": [
        "## Experiment with Gaussian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMoaoFUmqh5P"
      },
      "source": [
        "import cv2\n",
        "from skimage import io, img_as_float\n",
        "from skimage.filters import gaussian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufhwhNpAqtIu"
      },
      "source": [
        "# Conv\n",
        "gaussian_kernel = np.array([[1/16, 1/8, 1/16], [1/8, 1/4, 1/8], [1/16, 1/8, 1/16]])\n",
        "out_conv_img_np = cv2.filter2D(img_noisy_np, -1, gaussian_kernel, borderType=cv2.BORDER_CONSTANT)\n",
        "plot_results(out_conv_img_np, img_np, img_noisy_np)\n",
        "\n",
        "# Gaussian\n",
        "for sigma in [0.01, 0.05, 0.1, 0.3, 0.5, 1, 2]:\n",
        "  print(\"sigma =\", sigma)\n",
        "  out_gaussian_img_np = gaussian(img_noisy_np, sigma=sigma, mode='constant', cval=0.0)\n",
        "  plot_results(out_gaussian_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AJu3P-Etxxk"
      },
      "source": [
        "## Experiment with Bilateral"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQBmDniat4s0"
      },
      "source": [
        "from skimage.restoration import denoise_bilateral\n",
        "out_img_np = denoise_bilateral(np.squeeze(img_noisy_np), sigma_spatial=5, multichannel=False)\n",
        "plot_results(out_img_np.reshape((1, out_img_np.shape[0], out_img_np.shape[1])), img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zjNIZz_40Z9"
      },
      "source": [
        "from skimage.restoration import denoise_bilateral\n",
        "out_img_np = denoise_bilateral(np.squeeze(img_noisy_np), sigma_spatial=10, multichannel=False)\n",
        "plot_results(out_img_np.reshape((1, out_img_np.shape[0], out_img_np.shape[1])), img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOFd-GFT40ck"
      },
      "source": [
        "from skimage.restoration import denoise_bilateral\n",
        "out_img_np = denoise_bilateral(np.squeeze(img_noisy_np), sigma_spatial=15, multichannel=False)\n",
        "plot_results(out_img_np.reshape((1, 512, 512)), img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYo5_yspQyUz"
      },
      "source": [
        "##Experiments with Non-local Mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLhgkyiHQHN-"
      },
      "source": [
        "from skimage.restoration import denoise_nl_means, estimate_sigma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFSrBmPtRAa2"
      },
      "source": [
        "sigma_est = np.mean(estimate_sigma(img_noisy_np, multichannel=True))\n",
        "out_img_np = denoise_nl_means(img_noisy_np, h=1.15 * sigma_est, fast_mode=True,\n",
        "                               patch_size=5, patch_distance=3, multichannel=False)\n",
        "if len(out_img_np.shape)==3:\n",
        "  plot_results(out_img_np, img_np, img_noisy_np)\n",
        "else:\n",
        "  plot_results(out_img_np.reshape((1, out_img_np.shape[0], out_img_np.shape[1])), img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APJ0XBPS_pZF"
      },
      "source": [
        "out_img_np = denoise_nl_means(img_noisy_np, h=0.6*15./255., fast_mode=True,\n",
        "                               patch_size=5, patch_distance=6, multichannel=False)\n",
        "if len(out_img_np.shape)==3:\n",
        "  plot_results(out_img_np, img_np, img_noisy_np)\n",
        "else:\n",
        "  plot_results(out_img_np.reshape((1, out_img_np.shape[0], out_img_np.shape[1])), img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrOZ-6jjIyA6"
      },
      "source": [
        "## Experiments with BM3D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neiMQVc8cLtx"
      },
      "source": [
        "! pip install bm3d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgilyJQecH2a"
      },
      "source": [
        "import bm3d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-TGMD45cKEQ"
      },
      "source": [
        "for sigma_psd in [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5]:\n",
        "  BM3D_denoised_image = bm3d.bm3d(np.squeeze(np.transpose(img_noisy_np, (1, 2, 0))), sigma_psd=sigma_psd, stage_arg=bm3d.BM3DStages.HARD_THRESHOLDING)\n",
        "  print(\"sigma_psd = \", sigma_psd)\n",
        "  if len(BM3D_denoised_image.shape)==3:\n",
        "    plot_results(np.transpose(BM3D_denoised_image, (2, 0, 1)), img_np, img_noisy_np)\n",
        "  else:\n",
        "    plot_results(BM3D_denoised_image.reshape((1, BM3D_denoised_image.shape[0], BM3D_denoised_image.shape[1])), img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVWSxfxFcugW"
      },
      "source": [
        "BM3D_denoised_image = bm3d.bm3d(np.squeeze(np.transpose(img_noisy_np, (1, 2, 0))), sigma_psd=0.05, stage_arg=bm3d.BM3DStages.HARD_THRESHOLDING)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APhBrgsDb7ff"
      },
      "source": [
        "BM3D_denoised_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4BUM7DxbNML"
      },
      "source": [
        "n, bins, patches = plt.hist(BM3D_denoised_image.reshape(-1), bins=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbNXI4Ggb08r"
      },
      "source": [
        "plt.imshow(BM3D_denoised_image>0.18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9elKLoQ2cV_y"
      },
      "source": [
        "for threshold in np.linspace(0.0,0.2, 20):\n",
        "  modified_BM3D_denoised_image = BM3D_denoised_image * (BM3D_denoised_image>threshold)\n",
        "  plot_results(modified_BM3D_denoised_image.reshape((1, modified_BM3D_denoised_image.shape[0], modified_BM3D_denoised_image.shape[1])), img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYZTYDzZWm_K"
      },
      "source": [
        "## Experiments with pure TV denoising"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q9xAcHzWqbK"
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    from skimage.restoration import denoise_tv_chambolle\n",
        "except ImportError:\n",
        "    # skimage < 0.12\n",
        "    from skimage.filters import denoise_tv_chambolle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR8SzKXYXkdj"
      },
      "source": [
        "out_img_np = denoise_tv_chambolle(img_noisy_np, weight=0.02)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzjJi4-f5uUU"
      },
      "source": [
        "out_img_np = denoise_tv_chambolle(img_noisy_np, weight=0.1)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44g_o3ie5vio"
      },
      "source": [
        "out_img_np = denoise_tv_chambolle(img_noisy_np, weight=0.15)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7iFGpEpPy_8"
      },
      "source": [
        "##Experiments with L2 Norm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkpKbToHP4sR"
      },
      "source": [
        "out_img_np, mse_t = denoise(img_noisy_var, k=64, numit = 5000, rn = 0.0, loss_type='l2', lambda_ac=0, lambda_tv=0, debug=True)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h50FoW6msQla"
      },
      "source": [
        "##Experiments with L1 Norm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syAaS005MI5q"
      },
      "source": [
        "out_img_np, mse_t = denoise(img_noisy_var, k=128, numit = 5000, rn = 0.0, loss_type='l1', lambda_ac=0, lambda_tv=0, debug=True)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnJC_R-aRLYg"
      },
      "source": [
        "##Experiments with L1 Norm+TV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgWvN6YKbCVg"
      },
      "source": [
        "13298.24609375/0.03646152466535568"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC5MEmOWaEkw"
      },
      "source": [
        "out_img_np, mse_t = denoise(img_noisy_var, k=64, numit = 5000, rn = 0.0, loss_type='l1', lambda_ac=0, lambda_tv=1e5, debug=True)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AayQBrGftZU"
      },
      "source": [
        "out_img_np, mse_t = denoise(img_noisy_var, k=64, numit = 5000, rn = 0.0, loss_type='l1', lambda_ac=0, lambda_tv=5e4, debug=True)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cASoFDYSsVvX"
      },
      "source": [
        "##Experiments with L1 Norm+TV+AC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu-i8SRbcNRH"
      },
      "source": [
        "14160.3076171875/6.154358743515331e-06"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioKXlIVJhZ5K"
      },
      "source": [
        "out_img_np, mse_t = denoise(img_noisy_var, k=64, numit = 5000, rn = 0.0, loss_type='l1', lambda_ac=1e9, lambda_tv=1e5, debug=True)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqsC4hM8j7rB"
      },
      "source": [
        "out_img_np, mse_t = denoise(img_noisy_var, k=64, numit = 5000, rn = 0.0, loss_type='l1', lambda_ac=5e8, lambda_tv=1e5, debug=True)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxbUma7ej9qH"
      },
      "source": [
        "out_img_np, mse_t = denoise(img_noisy_var, k=64, numit = 5000, rn = 0.0, loss_type='l1', lambda_ac=1e8, lambda_tv=1e5, debug=True)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tQRa5h1sX1_"
      },
      "source": [
        "##Experiments with MSE+TV+Partial AC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NogqI4W6sbqM"
      },
      "source": [
        "img_noisy_np,img_noisy_var = get_noisy_img(sig=30, noise_same=False)\n",
        "out_img_np, mse_t = denoise(img_noisy_var, k=128, numit = 1900, rn = 0.0, lambda_ac=0, lambda_tv=1e-7, debug=True)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7TGJh34tf5d"
      },
      "source": [
        "ac = autocorrelation(torch.tensor((out_img_np-img_np).reshape((1,1,512,512))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT0hw6OVtm-O"
      },
      "source": [
        "plt.imshow(ac.cpu().numpy().reshape(512,512)[:10,:10], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w19tSB-ZxXIQ"
      },
      "source": [
        "loss_partial_ac(torch.tensor((out_img_np-img_np).reshape((1,1,512,512))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UamWQSQBuTJV"
      },
      "source": [
        "img_noisy_np,img_noisy_var = get_noisy_img(sig=30, noise_same=False)\n",
        "out_img_np, mse_t = denoise(img_noisy_var, k=128, numit = 1900, rn = 0.0, lambda_ac=5e2, lambda_tv=1e-7, debug=True)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJuUAwmiuUum"
      },
      "source": [
        "img_noisy_np,img_noisy_var = get_noisy_img(sig=30, noise_same=False)\n",
        "out_img_np, mse_t = denoise(img_noisy_var, k=128, numit = 1900, rn = 0.0, lambda_ac=1e3, lambda_tv=1e-7, debug=True)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccHxr4BLuV3X"
      },
      "source": [
        "img_noisy_np,img_noisy_var = get_noisy_img(sig=30, noise_same=False)\n",
        "out_img_np, mse_t = denoise(img_noisy_var, k=128, numit = 1900, rn = 0.0, lambda_ac=2e3, lambda_tv=1e-7, debug=True)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pi09fGnuWs_"
      },
      "source": [
        "img_noisy_np,img_noisy_var = get_noisy_img(sig=30, noise_same=False)\n",
        "out_img_np, mse_t = denoise(img_noisy_var, k=128, numit = 1900, rn = 0.0, lambda_ac=5e3, lambda_tv=1e-7, debug=True)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtphRcFzMrRS"
      },
      "source": [
        "##Experiments with 3D deep decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK5_wNN3MuFg"
      },
      "source": [
        "img = np.zeros((292, 288, 192))\n",
        "for i in range(192):\n",
        "  img_i = plt.imread(\"drive/My Drive/Full_Images/img_\"+str(i)+\".png\")\n",
        "  img[:,:,i] = img_i[:,:,0]\n",
        "img_np = img.reshape((1, 292, 288, 192))\n",
        "img_np = img_np[:,:,:,53:57]\n",
        "img_clean_var = np_to_var(img_np).type(dtype)\n",
        "sigma = 15./255.\n",
        "noise = np.random.normal(scale=sigma, size=img_np.shape)\n",
        "img_noisy_np = np.clip(img_np+noise, 0, 1).astype(np.float32)\n",
        "img_noisy_var = np_to_var(img_noisy_np).type(dtype)\n",
        "output_depth = img_np.shape[3] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU9iNJVKNpUT"
      },
      "source": [
        "out_img_np, mse_t = denoise(img_noisy_var, k=64, numit = 5000, rn = 0.0, loss_type='l2', lambda_ac=0, lambda_tv=0, debug=True)\n",
        "plot_results(out_img_np, img_np, img_noisy_np)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}